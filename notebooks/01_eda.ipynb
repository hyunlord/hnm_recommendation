{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H&M Recommendation System - Exploratory Data Analysis\n",
    "\n",
    "This notebook explores the H&M dataset to understand:\n",
    "- Data structure and quality\n",
    "- Customer behavior patterns\n",
    "- Product characteristics\n",
    "- Transaction trends\n",
    "- Key insights for recommendation system design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "# Add project root to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "project_root = Path('.').resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.utils.constants import *\n",
    "print(f\"Data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load articles data\n",
    "print(\"Loading articles data...\")\n",
    "articles_df = pd.read_csv(ARTICLES_PATH)\n",
    "print(f\"Articles shape: {articles_df.shape}\")\n",
    "articles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load customers data\n",
    "print(\"Loading customers data...\")\n",
    "customers_df = pd.read_csv(CUSTOMERS_PATH)\n",
    "print(f\"Customers shape: {customers_df.shape}\")\n",
    "customers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample of transactions (due to large size)\n",
    "print(\"Loading transactions data (sampling)...\")\n",
    "# First, let's check the total number of rows\n",
    "total_rows = sum(1 for line in open(TRANSACTIONS_PATH)) - 1\n",
    "print(f\"Total transactions: {total_rows:,}\")\n",
    "\n",
    "# Load a sample for initial exploration\n",
    "sample_size = 1_000_000\n",
    "transactions_sample = pd.read_csv(TRANSACTIONS_PATH, nrows=sample_size)\n",
    "transactions_sample['t_dat'] = pd.to_datetime(transactions_sample['t_dat'])\n",
    "print(f\"Sample transactions shape: {transactions_sample.shape}\")\n",
    "transactions_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in articles:\")\n",
    "print(articles_df.isnull().sum()[articles_df.isnull().sum() > 0])\n",
    "print(\"\\nMissing values in customers:\")\n",
    "print(customers_df.isnull().sum()[customers_df.isnull().sum() > 0])\n",
    "print(\"\\nMissing values in transactions:\")\n",
    "print(transactions_sample.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types\n",
    "print(\"Articles data types:\")\n",
    "print(articles_df.dtypes)\n",
    "print(\"\\nCustomers data types:\")\n",
    "print(customers_df.dtypes)\n",
    "print(\"\\nTransactions data types:\")\n",
    "print(transactions_sample.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Customer Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer age distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Age histogram\n",
    "customers_df['age'].hist(bins=50, ax=axes[0], edgecolor='black')\n",
    "axes[0].set_title('Customer Age Distribution')\n",
    "axes[0].set_xlabel('Age')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Age statistics\n",
    "age_stats = customers_df['age'].describe()\n",
    "axes[1].text(0.1, 0.5, f\"Age Statistics:\\n\\n{age_stats}\", \n",
    "             transform=axes[1].transAxes, fontsize=12, verticalalignment='center')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer membership and activity status\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Club member status\n",
    "customers_df['club_member_status'].value_counts().plot(kind='bar', ax=axes[0])\n",
    "axes[0].set_title('Club Member Status')\n",
    "axes[0].set_xlabel('Status')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Fashion news frequency\n",
    "customers_df['fashion_news_frequency'].value_counts().plot(kind='bar', ax=axes[1])\n",
    "axes[1].set_title('Fashion News Frequency')\n",
    "axes[1].set_xlabel('Frequency')\n",
    "axes[1].set_ylabel('Count')\n",
    "\n",
    "# Active status\n",
    "customers_df['Active'].value_counts().plot(kind='pie', ax=axes[2], autopct='%1.1f%%')\n",
    "axes[2].set_title('Customer Active Status')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Product Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top product groups\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Product group distribution\n",
    "articles_df['product_group_name'].value_counts().head(15).plot(kind='barh', ax=axes[0,0])\n",
    "axes[0,0].set_title('Top 15 Product Groups')\n",
    "axes[0,0].set_xlabel('Count')\n",
    "\n",
    "# Garment group distribution\n",
    "articles_df['garment_group_name'].value_counts().head(15).plot(kind='barh', ax=axes[0,1])\n",
    "axes[0,1].set_title('Top 15 Garment Groups')\n",
    "axes[0,1].set_xlabel('Count')\n",
    "\n",
    "# Department distribution\n",
    "articles_df['department_name'].value_counts().plot(kind='bar', ax=axes[1,0])\n",
    "axes[1,0].set_title('Department Distribution')\n",
    "axes[1,0].set_ylabel('Count')\n",
    "\n",
    "# Color distribution\n",
    "articles_df['colour_group_name'].value_counts().head(10).plot(kind='bar', ax=axes[1,1])\n",
    "axes[1,1].set_title('Top 10 Color Groups')\n",
    "axes[1,1].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Transaction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction date range\n",
    "print(f\"Transaction date range: {transactions_sample['t_dat'].min()} to {transactions_sample['t_dat'].max()}\")\n",
    "print(f\"Total days: {(transactions_sample['t_dat'].max() - transactions_sample['t_dat'].min()).days}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transactions over time\n",
    "daily_transactions = transactions_sample.groupby(transactions_sample['t_dat'].dt.date).size()\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "daily_transactions.plot()\n",
    "plt.title('Daily Transaction Count (Sample)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Transactions')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "transactions_sample['price'].hist(bins=50, edgecolor='black')\n",
    "plt.title('Price Distribution')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "transactions_sample['price'].apply(np.log1p).hist(bins=50, edgecolor='black')\n",
    "plt.title('Log Price Distribution')\n",
    "plt.xlabel('Log(Price + 1)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Price statistics:\")\n",
    "print(transactions_sample['price'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales channel distribution\n",
    "sales_channel_counts = transactions_sample['sales_channel_id'].value_counts()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sales_channel_counts.plot(kind='bar')\n",
    "plt.title('Sales Channel Distribution')\n",
    "plt.xlabel('Sales Channel ID')\n",
    "plt.ylabel('Number of Transactions')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Customer Purchase Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer purchase frequency\n",
    "customer_purchase_counts = transactions_sample['customer_id'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "customer_purchase_counts.hist(bins=50, edgecolor='black')\n",
    "plt.title('Customer Purchase Frequency Distribution')\n",
    "plt.xlabel('Number of Purchases')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "purchase_stats = customer_purchase_counts.describe()\n",
    "plt.text(0.1, 0.5, f\"Purchase Frequency Stats:\\n\\n{purchase_stats}\", \n",
    "         transform=plt.gca().transAxes, fontsize=12, verticalalignment='center')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product popularity\n",
    "product_purchase_counts = transactions_sample['article_id'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "product_purchase_counts.head(20).plot(kind='bar')\n",
    "plt.title('Top 20 Most Popular Products')\n",
    "plt.xlabel('Article ID')\n",
    "plt.ylabel('Number of Purchases')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "product_purchase_counts.hist(bins=50, edgecolor='black')\n",
    "plt.title('Product Purchase Frequency Distribution')\n",
    "plt.xlabel('Number of Purchases')\n",
    "plt.ylabel('Number of Products')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Insights for Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate key statistics\n",
    "print(\"=== Key Dataset Statistics ===\")\n",
    "print(f\"\\nTotal unique customers: {customers_df.shape[0]:,}\")\n",
    "print(f\"Total unique articles: {articles_df.shape[0]:,}\")\n",
    "print(f\"Total transactions (sample): {transactions_sample.shape[0]:,}\")\n",
    "\n",
    "print(f\"\\nAverage purchases per customer (sample): {customer_purchase_counts.mean():.2f}\")\n",
    "print(f\"Median purchases per customer (sample): {customer_purchase_counts.median():.2f}\")\n",
    "\n",
    "print(f\"\\nAverage purchases per product (sample): {product_purchase_counts.mean():.2f}\")\n",
    "print(f\"Median purchases per product (sample): {product_purchase_counts.median():.2f}\")\n",
    "\n",
    "print(f\"\\nSparsity of interaction matrix: {1 - (transactions_sample.shape[0] / (customers_df.shape[0] * articles_df.shape[0])):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify cold start problems\n",
    "print(\"=== Cold Start Analysis ===\")\n",
    "\n",
    "# Customers with few purchases\n",
    "few_purchase_customers = (customer_purchase_counts <= 2).sum()\n",
    "print(f\"\\nCustomers with ≤2 purchases: {few_purchase_customers:,} ({few_purchase_customers/len(customer_purchase_counts)*100:.1f}%)\")\n",
    "\n",
    "# Products with few purchases\n",
    "few_purchase_products = (product_purchase_counts <= 5).sum()\n",
    "print(f\"Products with ≤5 purchases: {few_purchase_products:,} ({few_purchase_products/len(product_purchase_counts)*100:.1f}%)\")\n",
    "\n",
    "# New customers (based on sample - would need full data for accurate count)\n",
    "last_week = transactions_sample['t_dat'].max() - timedelta(days=7)\n",
    "new_customers = transactions_sample[transactions_sample['t_dat'] >= last_week]['customer_id'].nunique()\n",
    "print(f\"\\nNew customers in last week (sample): {new_customers:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Processed Data Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data statistics for later use\n",
    "data_stats = {\n",
    "    'n_customers': customers_df.shape[0],\n",
    "    'n_articles': articles_df.shape[0],\n",
    "    'n_transactions_total': total_rows,\n",
    "    'date_min': str(transactions_sample['t_dat'].min()),\n",
    "    'date_max': str(transactions_sample['t_dat'].max()),\n",
    "    'avg_customer_age': customers_df['age'].mean(),\n",
    "    'sparsity': 1 - (total_rows / (customers_df.shape[0] * articles_df.shape[0]))\n",
    "}\n",
    "\n",
    "import json\n",
    "stats_path = project_root / 'experiments' / 'data_stats.json'\n",
    "stats_path.parent.mkdir(exist_ok=True)\n",
    "with open(stats_path, 'w') as f:\n",
    "    json.dump(data_stats, f, indent=2)\n",
    "\n",
    "print(f\"Data statistics saved to: {stats_path}\")\n",
    "print(json.dumps(data_stats, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Key Findings\n",
    "\n",
    "1. **Data Scale**: Large-scale dataset with ~1.37M customers, ~105K products, and ~31M transactions\n",
    "2. **Sparsity**: Extremely sparse interaction matrix (>99.99% sparse)\n",
    "3. **Customer Behavior**: Most customers have few purchases (long-tail distribution)\n",
    "4. **Product Popularity**: Few products dominate purchases (power law distribution)\n",
    "5. **Cold Start**: Significant cold start problem for both users and items\n",
    "6. **Temporal Patterns**: Clear seasonal/temporal patterns in purchase behavior\n",
    "\n",
    "These insights will guide our recommendation system design:\n",
    "- Need efficient sparse matrix handling\n",
    "- Must address cold start problem (content-based features important)\n",
    "- Should consider temporal dynamics\n",
    "- Popular items baseline likely to be strong"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}