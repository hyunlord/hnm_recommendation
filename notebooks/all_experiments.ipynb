{ "cells": [  {   "cell_type": "markdown",   "metadata": {},   "source": [    "# H&M Recommendation Models: All Experiments"   ]  },  {   "cell_type": "markdown",   "metadata": {},   "source": [    "This notebook contains all experiments from basic baselines to a hybrid model.\n",    "Run the cells sequentially from top to bottom."   ]  },  {   "cell_type": "markdown",   "metadata": {},   "source": [    "## 1. Setup"   ]  },  {   "cell_type": "code",   "execution_count": null,   "metadata": {},   "outputs": [],   "source": [    "import sys\n",    "sys.path.append('../src')\n",    "\n",    "import pandas as pd\n",    "import numpy as np\n",    "import torch\n",    "import pytorch_lightning as pl\n",    "from pytorch_lightning.callbacks import ModelCheckpoint\n",    "import glob\n",    "\n",    "from data import HnMLightningDataModule\n",    "from models import NeuMF\n",    "from tqdm.notebook import tqdm\n",    "from sklearn.feature_extraction.text import TfidfVectorizer\n",    "from sklearn.metrics.pairwise import cosine_similarity\n",    "from sklearn.preprocessing import MinMaxScaler"   ]  },  {   "cell_type": "markdown",   "metadata": {},   "source": [    "## 2. Load Data"   ]  },  {   "cell_type": "code",   "execution_count": null,   "metadata": {},   "outputs": [],   "source": [    "dm = HnMLightningDataModule(data_dir='../data', batch_size=2048, num_workers=4)\n",    "dm.setup()\n",    "\n",    "articles_df = pd.read_csv('../data/articles.csv', dtype={'article_id': str})\n",    "articles_df = articles_df.set_index('article_id')"   ]  },  {   "cell_type": "markdown",   "metadata": {},   "source": [    "## 3. Evaluation Metric (MAP@12)"   ]  },  {   "cell_type": "code",   "execution_count": null,   "metadata": {},   "outputs": [],   "source": [    "def apk(actual, predicted, k=12):\n",    "    if not actual:\n",    "        return 0.0\n",    "    if len(predicted) > k:\n",    "        predicted = predicted[:k]\n",    "    score = 0.0\n",    "    num_hits = 0.0\n",    "    for i, p in enumerate(predicted):\n",    "        if p in actual and p not in predicted[:i]:\n",    "            num_hits += 1.0\n",    "            score += num_hits / (i + 1.0)\n",    "    return score / min(len(actual), k)\n",    "\n",    "def mapk(actual, predicted, k=12):\n",    "    if not actual or not predicted:\n",    "        return 0.0\n",    "    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])\n",    "\n",    "val_true_items = dm.val_df.groupby('customer_id')['article_id'].apply(list).to_dict()\n",    "val_users = list(val_true_items.keys())\n",    "actuals = [val_true_items.get(user, []) for user in val_users]"   ]  },  {   "cell_type": "markdown",   "metadata": {},   "source": [    "## 4. Model 1: Most Popular Items"   ]  },  {   "cell_type": "code",   "execution_count": null,   "metadata": {},   "outputs": [],   "source": [    "popular_items = dm.train_df['article_id'].value_counts().index[:12].tolist()\n",    "popular_predictions = [popular_items] * len(val_users)\n",    "map_popular = mapk(actuals, popular_predictions, k=12)\n",    "print(f\"[Result] Most Popular Items MAP@12: {map_popular:.6f}\")"   ]  },  {   "cell_type": "markdown",   "metadata": {},   "source": [    "## 5. Model 2: NeuMF"   ]  },  {   "cell_type": "markdown",   "metadata": {},   "source": [    "### 5.1. Training"   ]  },  {   "cell_type": "code",   "execution_count": null,   "metadata": {},   "outputs": [],   "source": [    "model = NeuMF(num_users=dm.num_users, num_items=dm.num_items)\n",    "checkpoint_callback = ModelCheckpoint(monitor='val_loss', dirpath='../models/', filename='best-neumf-model', save_top_k=1, mode='min')\n",    "trainer = pl.Trainer(max_epochs=1, accelerator='auto', logger=True, callbacks=[checkpoint_callback])\n",    "trainer.fit(model, dm)"   ]  },  {   "cell_type": "markdown",   "metadata": {},   "source": [    "### 5.2. Evaluation"   ]  },  {   "cell_type": "code",   "execution_count": null,   "metadata": {},   "outputs": [],   "source": [    "best_model_path = checkpoint_callback.best_model_path\n",    "print(f\"Loading best NeuMF model from: {best_model_path}\")\n",    "neumf_model = NeuMF.load_from_checkpoint(best_model_path)\n",    "neumf_model.eval()\n",    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",    "neumf_model.to(device)\n",    "\n",    "all_item_ids_mapped = list(dm.item_map.keys())\n",    "all_item_indices = torch.tensor(list(dm.item_map.values()), dtype=torch.long).to(device)\n",    "\n",    "neumf_predictions = []\n",    "for user_id_str in tqdm(val_users, desc=\"Generating NeuMF Predictions\"):\n",    "    user_idx = dm.user_map.get(user_id_str)\n",    "    if user_idx is not None:\n",    "        user_tensor = torch.tensor([user_idx] * len(all_item_indices), dtype=torch.long).to(device)\n",    "        with torch.no_grad():\n",    "            scores = neumf_model(user_tensor, all_item_indices)\n",    "        top_indices = torch.argsort(scores, descending=True)[:12]\n",    "        neumf_predictions.append([all_item_ids_mapped[i] for i in top_indices.cpu().numpy()])\n",    "    else:\n",    "        neumf_predictions.append(popular_items)\n",    "\n",    "map_neumf = mapk(actuals, neumf_predictions, k=12)\n",    "print(f\"[Result] NeuMF Model MAP@12: {map_neumf:.6f}\")"   ]  },  {   "cell_type": "markdown",   "metadata": {},   "source": [    "## 6. Model 3: Content-Based Filtering"   ]  },  {   "cell_type": "code",   "execution_count": null,   "metadata": {},   "outputs": [],   "source": [    "# Content Feature Engineering\n",    "for col in ['prod_name', 'product_type_name', 'product_group_name', 'graphical_appearance_name', 'colour_group_name', 'department_name', 'index_name', 'section_name', 'garment_group_name']:\n",    "    articles_df[col] = articles_df[col].fillna('')\n",    "articles_df['content'] = articles_df.apply(lambda row: ' '.join(row.astype(str)), axis=1)\n",    "\n",    "# TF-IDF Vectorization\n",    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",    "tfidf_matrix = tfidf.fit_transform(articles_df['content'])\n",    "article_id_to_idx = {id: i for i, id in enumerate(articles_df.index)}\n",    "\n",    "# Generate Predictions\n",    "user_history = dm.train_df.groupby('customer_id')['article_id'].apply(list).to_dict()\n",    "content_predictions = []\n",    "for user_id in tqdm(val_users, desc=\"Generating Content-Based Predictions\"):\n",    "    history_articles = user_history.get(user_id, [])\n",    "    history_indices = [article_id_to_idx[art_id] for art_id in history_articles if art_id in article_id_to_idx]\n",    "    if history_indices:\n",    "        user_profile_vector = tfidf_matrix[history_indices].mean(axis=0)\n",    "        cosine_sims = cosine_similarity(user_profile_vector, tfidf_matrix).flatten()\n",    "        top_indices = np.argsort(cosine_sims)[::-1][:50]\n",    "        rec_items = [articles_df.index[i] for i in top_indices if articles_df.index[i] not in history_articles]\n",    "        content_predictions.append(rec_items[:12])\n",    "    else:\n",    "        content_predictions.append(popular_items)\n",    "\n",    "map_content = mapk(actuals, content_predictions, k=12)\n",    "print(f\"[Result] Content-Based Filtering MAP@12: {map_content:.6f}\")"   ]  },  {   "cell_type": "markdown",   "metadata": {},   "source": [    "## 7. Model 4: Hybrid (NeuMF + Content-Based)"   ]  },  {   "cell_type": "code",   "execution_count": null,   "metadata": {},   "outputs": [],   "source": [    "hybrid_predictions = []\n",    "alpha = 0.5 # Weight for NeuMF model\n",    "scaler = MinMaxScaler()\n",    "\n",    "for i, user_id_str in enumerate(tqdm(val_users, desc=\"Generating Hybrid Predictions\")):\n",    "    # Get NeuMF scores (already calculated)\n",    "    neumf_recs = neumf_predictions[i]\n",    "    neumf_scores = {art_id: (12-rank) for rank, art_id in enumerate(neumf_recs)}\n",    "    \n",    "    # Get Content-based scores (already calculated)\n",    "    content_recs = content_predictions[i]\n",    "    content_scores = {art_id: (12-rank) for rank, art_id in enumerate(content_recs)}\n",    "    \n",    "    # Combine scores\n",    "    hybrid_scores = {}\n",    "    all_recs = set(neumf_recs) | set(content_recs)\n",    "    for art_id in all_recs:\n",    "        hybrid_scores[art_id] = alpha * neumf_scores.get(art_id, 0) + (1 - alpha) * content_scores.get(art_id, 0)\n",    "        \n",    "    # Sort and get top 12\n",    "    sorted_hybrid = sorted(hybrid_scores.items(), key=lambda item: item[1], reverse=True)[:12]\n",    "    hybrid_predictions.append([art_id for art_id, score in sorted_hybrid])\n",    "\n",    "map_hybrid = mapk(actuals, hybrid_predictions, k=12)\n",    "print(f\"[Result] Hybrid Model MAP@12: {map_hybrid:.6f}\")"   ]  } ], "metadata": {  "kernelspec": {   "display_name": "Python 3",   "language": "python",   "name": "python3"  },  "language_info": {   "codemirror_mode": {    "name": "ipython",    "version": 3   },   "file_extension": ".py",   "mimetype": "text/x-python",   "name": "python",   "nbconvert_exporter": "python",   "pygments_lexer": "ipython3",   "version": "3.9.7"  } }, "nbformat": 4, "nbformat_minor": 4}